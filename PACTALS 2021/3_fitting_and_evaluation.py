# -*- coding: utf-8 -*-
"""Fitting and Evaluation.ipynb의 사본

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15lrlbcBXYXKIB9p3q8MoFigPlY8JbAnX
"""

# Load packages
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

pip install lifelines

# Read datasets needed
from google.colab import files 
uploaded = files.upload()

import io
feature = pd.read_csv(io.BytesIO(uploaded['0817_X_imputed.csv'])) 
target = pd.read_csv(io.BytesIO(uploaded['0817_optimal_target.csv'])) #target means 'time to dietary consistency change'

feature.columns

opt_data = pd.merge(feature, target, on = 'SubjectID').drop(columns=['Unnamed: 0_x', 'Unnamed: 0_y'])

# add meta feature 'mean_Q1_2_3_mouth'
opt_data['mean_Q1_2_3_mouth'] = opt_data['mean_Q1_Speech'] + opt_data['mean_Q2_Salivation'] + opt_data['mean_Q3_Swallowing']
opt_data = opt_data[['SubjectID','Age', 'onset_delta', 'fvc_mean', 'Creatinine_mean', 
                       'mean_Q1_2_3_mouth',   'mean_Q5_Cutting', 'mean_Q7_Turning_in_Bed', 
                       'slope_Q1_Speech', 'slope_Q3_Swallowing', 
                      'weight_slope', 'status_opt', 'time_opt']]

y = opt_data[['status_opt']] # y means whether dietary consistency change has occured or not

# Separate 5 subjects for demonstration purpose
df_test = opt_data.sample(n=5, random_state = 12)
testID_list = list(df_test['SubjectID'])

# The others are used as train set
df_train = opt_data[~(opt_data['SubjectID'].isin(testID_list))]
df_train = df_train.drop(columns = 'SubjectID')
y_train = df_train[['status_opt']]

df_train

"""## 1. Fitting survival models

##1) Accelarated Failure Time model

###(1) Tuning hyperparameters: GridSearchCV for AFT
"""

from sklearn.model_selection import GridSearchCV

aft_params ={ 'penalizer': [0, 1e-4, 1e-3, 1e-2, 0.1, 0.2, 0.5],
              'l1_ratio' : [0, 1e-4, 1e-3, 1e-2, 0.1, 0.2, 0.5]  }

from lifelines import WeibullAFTFitter
from lifelines.utils.sklearn_adapter import sklearn_adapter

X_aft = df_train.drop(columns = 'time_opt')
y_aft = df_train['time_opt']

base_class2 = sklearn_adapter(WeibullAFTFitter, event_col = 'status_opt')
aft = base_class2()

grid_cv2 = GridSearchCV(aft, param_grid = aft_params, cv = 3, n_jobs = 1)
grid_cv2.fit(X_aft, y_aft)

#Result
print(grid_cv2.best_score_)
print(grid_cv2.best_params_)

"""### (2) Fitting AFT model"""

from lifelines import WeibullAFTFitter

aft = WeibullAFTFitter(penalizer = 0.2, l1_ratio = 0.2)
aft.fit(df_train, duration_col='time_opt', event_col='status_opt', ancillary=False)

aft.print_summary() # Prints accelerated failure rate & p-value of each feature

# Print 95% CI AFRs in a plot
from lifelines import utils
from numpy import exp

plt.figure(figsize=(6.3,7.8))
ax = plt.gca()

z = utils.inv_normal_cdf(1 - aft.alpha / 2)
columns = [('lambda_',                    'slope_Q3_Swallowing'),
            ('lambda_',       'mean_Q1_2_3_mouth'),
            ('lambda_',               'slope_Q1_Speech'),
            ('lambda_',        'mean_Q7_Turning_in_Bed'),
            ('lambda_',            'weight_slope'),
            ('lambda_',  'mean_Q5_Cutting'),
            ('lambda_',    'fvc_mean'),
            ('lambda_',        'Creatinine_mean'),
            ('lambda_',    'onset_delta'),
            ('lambda_',           'Age')]

yaxis_locations = list(range(len(columns)))
log_afr = aft.params_.loc[columns].values.copy()

order = list(range(len(columns) - 1, -1, -1))

afr = exp(log_afr)
upper_errors = afr * (exp(z * aft.standard_errors_[columns].values) - 1)
lower_errors = afr * (1 - exp(-z * aft.standard_errors_[columns].values))
ax.errorbar(
      afr[order],
      yaxis_locations,
      xerr=np.vstack([lower_errors[order], upper_errors[order]]),
      c = "k",
      fmt = "s",
      markerfacecolor = 'white',
      markeredgewidth = 1.25,
      elinewidth = 1.25,
      capsize = 3   
)

ax.set_xlabel("AFR (%g%% CI)" % ((1 - aft.alpha) * 100))

best_ylim = ax.get_ylim()
ax.vlines(1 , -2, len(columns) + 1, linestyles="dashed", linewidths=1, alpha=0.65, color="k")
ax.set_ylim(best_ylim)

tick_labels = [columns[i] for i in order]

ax.set_yticks(yaxis_locations)
ax.set_yticklabels(tick_labels)
ax.yaxis.set_visible(True)

from matplotlib import pyplot as plt

aft = WeibullAFTFitter().fit(df_train, 'time_opt', 'status_opt', ancillary=False)
plt.figure(figsize=(6,10))
aft.plot() # Print 95% CI log(AFR) in a plot

"""###(3) Re-fitting without insignificant feature"""

# features with p-value higher than 0.05 are excluded
df_train_finalaft = df_train[['Age', 'onset_delta', 'fvc_mean', 'mean_Q1_2_3_mouth', 'mean_Q7_Turning_in_Bed',
       'slope_Q1_Speech', 'slope_Q3_Swallowing', 'weight_slope', 'status_opt', 'time_opt']]

aft = WeibullAFTFitter(penalizer = 0.2, l1_ratio = 0.2)
aft.fit(df_train_finalaft, duration_col='time_opt', event_col='status_opt', ancillary=False)

aft.print_summary()

"""## 2) Cox Proportional Hazard Model

### (1) Tuning hyperparameter: GridSearchCV for Cox
"""

from sklearn.model_selection import GridSearchCV

cox_params ={'penalizer': [0, 1e-4, 1e-3, 1e-2, 0.1, 0.2, 0.5],
            'l1_ratio' : [0, 1e-4, 1e-3, 1e-2, 0.1, 0.2, 0.5] }

from lifelines import CoxPHFitter
from lifelines.utils.sklearn_adapter import sklearn_adapter

X_cox = df_train.drop(columns = 'time_opt')
y_cox = df_train['time_opt']

base_class = sklearn_adapter(CoxPHFitter, event_col = 'status_opt')
cph = base_class()

grid_cv = GridSearchCV(cph, param_grid = cox_params, cv = 3, n_jobs = 1)
grid_cv.fit(X_cox, y_cox)

# Result
print(grid_cv.best_score_)
print(grid_cv.best_params_)

"""### (2) Fitting CoxPH model"""

from lifelines import CoxPHFitter
cph = CoxPHFitter(penalizer=0.1, l1_ratio = 0.2)
cph.fit(df_train, 'time_opt', event_col='status_opt')
cph.print_summary() # Prints hazard ratio & p-value of each feature

# Testing proportional-hazard assumption
print(cph.check_assumptions(df_train))

# Print 95% CI Hazard ratios in a plot
plt.figure(figsize = (6.3,7.8))
ax = cph.plot(hazard_ratios=True, c='k', marker='D')
ax.yaxis.set_visible(True) #HR >1, or log(HR)>0 means that a feature increases the risk of event occurence

df_train.columns

"""### (3) Re-fitting without insignificant feature"""

# features with p-value higher than 0.05 are excluded
df_train_finalcox = df_train[['Age', 'onset_delta', 'fvc_mean',
       'mean_Q1_2_3_mouth', 'mean_Q7_Turning_in_Bed',
       'slope_Q1_Speech', 'slope_Q3_Swallowing',
        'weight_slope', 'status_opt', 'time_opt']]

from lifelines import CoxPHFitter
cph = CoxPHFitter(penalizer=0.1, l1_ratio = 0.2)
cph.fit(df_train_finalcox, 'time_opt', event_col='status_opt')
cph.print_summary()

# Print 95% CI Hazard ratios in a plot
plt.figure(figsize=(6.3, 7.8))
ax = cph.plot(hazard_ratios=True, c='k', marker='D')
ax.yaxis.set_visible(True)

"""## 3) Random Survival Forest model"""

!pip install --upgrade pip
!pip uninstall --yes --quiet osqp
!pip install -U scikit-survival

from sksurv.ensemble import RandomSurvivalForest

# Random Survival Forests requires array-type data, thus additional preprocessing was needed
dic = {1:True, 0:False}

df_train_rsf = df_train.iloc[:, -2:][['status_opt', 'time_opt']]
df_train_rsf = df_train_rsf.replace({'status_opt':dic})

arr_1 = list(tuple(x) for x in df_train_rsf.to_records(index=False))
dt = np.dtype('bool, float')
y_train_rsf = np.array(arr_1, dtype=dt)
y_train_rsf.dtype.names=['cens', 'time']
y_train_rsf

"""###(1) GridSearchCV for RSF"""

from sklearn.model_selection import GridSearchCV

params ={ 'n_estimators':[100],
          'max_features':['auto', 'sqrt','log2', None],
          'min_samples_leaf':[8,12,18],
          'min_samples_split':[8,16,20] }

rf = RandomSurvivalForest(random_state=20, n_jobs=-1)
grid_cv3 = GridSearchCV(rf, param_grid=params, cv=2, n_jobs=-1)
GG = grid_cv3.fit(df_train.iloc[:,:-2], y_train_rsf)

# Result
print(grid_cv3.best_score_)
print(grid_cv3.best_params_)

"""###(2) Fitting RSF model"""

rsf = RandomSurvivalForest(n_estimators=100,
                           min_samples_split=8,
                           min_samples_leaf=18,
                           max_features="auto",
                           n_jobs=-1,
                           random_state=20)
rsf.fit(df_train.iloc[:,:-2], y_train_rsf)

feature_names = df_train.iloc[:, :-2].columns.tolist()
feature_names

pip install eli5

import eli5
from eli5.sklearn import PermutationImportance

perm = PermutationImportance(rsf, n_iter=15, random_state=20)
perm.fit(df_train.iloc[:, :-2], y_train_rsf)

eli5.explain_weights_df(perm, feature_names=feature_names).describe()

eli5.show_weights(perm, feature_names=feature_names)

# Because 'eli5.show_weights' only provides html object, Feature importance written as a dataframe in csv dtype were separately made in excel.
from google.colab import files 
uploaded = files.upload()

import io
Feat_imp = pd.read_csv(io.BytesIO(uploaded['BB2 final.csv']))

Feat_imp = Feat_imp[['Unnamed: 2', 'weight', 'max', 'min']]

Feat_imp

Feat_imp = Feat_imp.transpose()
Feat_imp.columns = ['mean_Q1_2_3_mouth','slope_Q3_Swallowing', 'fvc_mean','onset_delta', 'mean_Q7_Turning_in_Bed', 'slope_Q1_Speech',
         'weight_slope',  'Age', 'mean_Q5_Cutting	', 'Creatinine_mean']
Feat_imp = Feat_imp.iloc[1:, :]
Feat_imp

df = pd.DataFrame(data=Feat_imp, columns=['mean_Q1_2_3_mouth','slope_Q3_Swallowing', 'fvc_mean','onset_delta', 'mean_Q7_Turning_in_Bed', 'slope_Q1_Speech',
         'weight_slope',  'Age', 'mean_Q5_Cutting	', 'Creatinine_mean'])

import matplotlib
matplotlib.rc('axes',edgecolor='k')

fig, ax = plt.subplots()
ax.grid(False)
fig.set_size_inches(10, 8)
sns.barplot(x="value", y="variable", data=pd.melt(df), color='white', edgecolor='k', dodge=False)
ax.set_xlabel(' ')
ax.set_xlim([-0.005,0.5])
ax.set_ylabel('')
ax.yaxis.set_visible(True)

"""### (3) Re-fitting without insignificant feature"""

# features with feature-weight less than 0.01 are excluded
df_train_finalrsf = df_train[['onset_delta', 'fvc_mean',
       'mean_Q1_2_3_mouth', 'mean_Q7_Turning_in_Bed',
       'slope_Q1_Speech', 'slope_Q3_Swallowing', 
        'weight_slope', 'status_opt', 'time_opt']]

rsf = RandomSurvivalForest(n_estimators=100,
                           min_samples_split=8,
                           min_samples_leaf=18,
                           max_features="auto",
                           n_jobs=-1,
                           random_state=20)
rsf.fit(df_train_finalrsf.iloc[:,:-2], y_train_rsf)

feature_names = df_train_finalrsf.iloc[:, :-2].columns.tolist()

perm = PermutationImportance(rsf, n_iter=15, random_state=20)
perm.fit(df_train_finalrsf.iloc[:, :-2], y_train_rsf)

eli5.show_weights(perm, feature_names=feature_names)

"""## 2. Evaluating model performances

## 1) Repeated 5-fold cross validation on Training set

### (1) Accelerated Failure Time
"""

from lifelines import WeibullAFTFitter
aft = WeibullAFTFitter(penalizer = 0.2, l1_ratio = 0.2)
C_Idx1 = np.array([])
random_num_list = [10,20,30,40,50,60,70,80,90,100]

for i in random_num_list:
    df_train_aft = df_train_finalaft.sample(n=len(df_train_finalaft), random_state=i)
    
    aft.fit(df_train_aft.iloc[0:2047,:], 'time_opt', event_col='status_opt')
    sco_1 = concordance_index(df_train_aft.iloc[2047:,:]['time_opt'], aft.predict_median(df_train_aft.iloc[2047:,:]), df_train_aft.iloc[2047:,:]['status_opt'])
    
    aft.fit(df_train_aft.iloc[512:,:], 'time_opt', event_col='status_opt')
    sco_2 = concordance_index(df_train_aft.iloc[0:512,:]['time_opt'], aft.predict_median(df_train_aft.iloc[0:512,:]), df_train_aft.iloc[0:512,:]['status_opt'])

    aft.fit(pd.concat([df_train_aft.iloc[0:512],df_train_aft.iloc[1024:]]), 'time_opt', event_col='status_opt')
    sco_3 = concordance_index(df_train_aft.iloc[512:1024,:]['time_opt'], aft.predict_median(df_train_aft.iloc[512:1024,:]), df_train_aft.iloc[512:1024,:]['status_opt'])

    aft.fit(pd.concat([df_train_aft.iloc[0:1024],df_train_aft.iloc[1536:]]), 'time_opt', event_col='status_opt')
    sco_4 = concordance_index(df_train_aft.iloc[1024:1536,:]['time_opt'], aft.predict_median(df_train_aft.iloc[1024:1536,:]), df_train_aft.iloc[1024:1536,:]['status_opt'])

    aft.fit(pd.concat([df_train_aft.iloc[0:1536],df_train_aft.iloc[2047:]]), 'time_opt', event_col='status_opt')
    sco_5 = concordance_index(df_train_aft.iloc[1536:2047,:]['time_opt'], aft.predict_median(df_train_aft.iloc[1536:2047,:]), df_train_aft.iloc[1536:2047,:]['status_opt'])
    
    C_Idx1 = np.append (C_Idx1, [sco_1, sco_2, sco_3, sco_4, sco_5])
print(C_Idx1)

"""### (2) Cox proportional hazard model"""

from lifelines.utils import concordance_index

# 5-fold cross validation is repeated 10 times, 50 C-index values are returned as a result
cph = CoxPHFitter(penalizer = 0.1, l1_ratio = 0.2)
C_Idx2 = np.array([])
random_num_list = [10,20,30,40,50,60,70,80,90,100]

for i in random_num_list:
    df_train_cox = df_train_finalcox.sample(n=len(df_train_finalcox), random_state=i)
    
    cph.fit(df_train_cox.iloc[0:2047,:], 'time_opt', event_col='status_opt')
    sco_1 = concordance_index(df_train_cox.iloc[2047:,:]['time_opt'], -cph.predict_partial_hazard(df_train_cox.iloc[2047:,:]), df_train_cox.iloc[2047:,:]['status_opt'])
    
    cph.fit(df_train_cox.iloc[512:,:], 'time_opt', event_col='status_opt')
    sco_2 = concordance_index(df_train_cox.iloc[0:512,:]['time_opt'], -cph.predict_partial_hazard(df_train_cox.iloc[0:512,:]), df_train_cox.iloc[0:512,:]['status_opt'])

    cph.fit(pd.concat([df_train_cox.iloc[0:512],df_train_cox.iloc[1024:]]), 'time_opt', event_col='status_opt')
    sco_3 = concordance_index(df_train_cox.iloc[512:1024,:]['time_opt'], -cph.predict_partial_hazard(df_train_cox.iloc[512:1024,:]), df_train_cox.iloc[512:1024,:]['status_opt'])

    cph.fit(pd.concat([df_train_cox.iloc[0:1024],df_train_cox.iloc[1536:]]), 'time_opt', event_col='status_opt')
    sco_4 = concordance_index(df_train_cox.iloc[1024:1536,:]['time_opt'], -cph.predict_partial_hazard(df_train_cox.iloc[1024:1536,:]), df_train_cox.iloc[1024:1536,:]['status_opt'])

    cph.fit(pd.concat([df_train_cox.iloc[0:1536],df_train_cox.iloc[2047:]]), 'time_opt', event_col='status_opt')
    sco_5 = concordance_index(df_train_cox.iloc[1536:2047,:]['time_opt'], -cph.predict_partial_hazard(df_train_cox.iloc[1536:2047,:]), df_train_cox.iloc[1536:2047,:]['status_opt'])
    
    C_Idx2 = np.append (C_Idx2, [sco_1, sco_2, sco_3, sco_4, sco_5])

print(C_Idx2)

"""### (3) Random Survival Forest"""

df_train_finalrsf2 = df_train_finalrsf.replace({'status_opt':dic})
df_train_finalrsf2

C_Idx3 = np.array([])
random_num_list = [10,20,30,40,50,60,70,80,90,100]

for i in random_num_list:
    df_train_rsf = df_train_finalrsf2.sample(n=len(df_train_finalrsf2), random_state=i)
    
    y_train_rsf_1 = np.array(list(tuple(x) for x in df_train_rsf.iloc[:2047,-2:].to_records(index=False)), dtype=dt)
    y_test_rsf_1 = np.array(list(tuple(x) for x in df_train_rsf.iloc[2047:,-2:].to_records(index=False)), dtype=dt)
    
    y_train_rsf_2 = np.array(list(tuple(x) for x in df_train_rsf.iloc[512:,-2:].to_records(index=False)), dtype=dt)
    y_test_rsf_2 = np.array(list(tuple(x) for x in df_train_rsf.iloc[0:512,-2:].to_records(index=False)), dtype=dt)
    
    y_train_rsf_3 = np.array(list(tuple(x) for x in pd.concat([df_train_rsf.iloc[0:512,-2:],df_train_rsf.iloc[1024:,-2:]]).to_records(index=False)), dtype=dt)
    y_test_rsf_3 = np.array(list(tuple(x) for x in df_train_rsf.iloc[512:1024,-2:].to_records(index=False)), dtype=dt)
    
    y_train_rsf_4 = np.array(list(tuple(x) for x in pd.concat([df_train_rsf.iloc[0:1024,-2:],df_train_rsf.iloc[1536:,-2:]]).to_records(index=False)), dtype=dt)
    y_test_rsf_4 = np.array(list(tuple(x) for x in df_train_rsf.iloc[1024:1536,-2:].to_records(index=False)), dtype=dt)
    
    y_train_rsf_5 = np.array(list(tuple(x) for x in pd.concat([df_train_rsf.iloc[0:1536,-2:],df_train_rsf.iloc[2047:,-2:]]).to_records(index=False)), dtype=dt)
    y_test_rsf_5 = np.array(list(tuple(x) for x in df_train_rsf.iloc[1536:2047,-2:].to_records(index=False)), dtype=dt)
    
    
    rsf.fit(df_train_rsf.iloc[0:2047,:-2], y_train_rsf_1)
    sco_1 = rsf.score(df_train_rsf.iloc[2047:,:-2], y_test_rsf_1)
    
    rsf.fit(df_train_rsf.iloc[512:,:-2], y_train_rsf_2)
    sco_2 = rsf.score(df_train_rsf.iloc[0:512,:-2], y_test_rsf_2)
    
    rsf.fit(pd.concat([df_train_rsf.iloc[0:512,:-2],df_train_rsf.iloc[1024:,:-2]]), y_train_rsf_3)
    sco_3 = rsf.score(df_train_rsf.iloc[512:1024,:-2], y_test_rsf_3)
    
    rsf.fit(pd.concat([df_train_rsf.iloc[0:1024,:-2],df_train_rsf.iloc[1536:,:-2]]), y_train_rsf_4)
    sco_4 = rsf.score(df_train_rsf.iloc[1024:1536,:-2], y_test_rsf_4)
    
    rsf.fit(pd.concat([df_train_rsf.iloc[0:1536,:-2],df_train_rsf.iloc[2047:,:-2]]), y_train_rsf_5)
    sco_5 = rsf.score(df_train_rsf.iloc[1536:2047,:-2], y_test_rsf_5)
    
    C_Idx3 = np.append (C_Idx3, [sco_1, sco_2, sco_3, sco_4, sco_5])

print(C_Idx3)

"""### (4) Comparing C-index values between Cox & AFT & RSF"""

df = pd.DataFrame([C_Idx1, C_Idx2,C_Idx3], index=['CoxPH', 'RSF','AFT'])
df2 = df.transpose()

colors = ['#000000', '#000000', '#ff7f00']
colors_setosa = dict(color=colors[0])
colors_versicolor = dict(color=colors[1])
colors_versicolor2 = dict(color=colors[2])

aft_median = np.median(df2['AFT'])
cox_median = np.median(df2['CoxPH'])
rsf_median = np.median(df2['RSF'])
aft_std = np.std(df2['AFT'])
cox_std = np.std(df2['CoxPH'])
rsf_std = np.std(df2['RSF'])

fig, ax = plt.subplots(figsize=(9,4.5))
ax = df2.boxplot(column=[ 'RSF', 'CoxPH', 'AFT'], vert=False, color = 'k')
plt.annotate(str(np.round(aft_median,3)), xy=(aft_median, 0.8)
                , xytext=(aft_median, 3.205) , fontsize=12)
plt.annotate(str(np.round(cox_median,3)), xy=(aft_median, 0.8)
                , xytext=(cox_median, 2.205) , fontsize=12)
plt.annotate(str(np.round(rsf_median,3)), xy=(aft_median, 0.8)
                , xytext=(rsf_median, 1.205) , fontsize=12)
plt.xlim([.6,1.0])
plt.xlabel('Concordance index')
plt.show()

print(aft_median)
print(cox_median)
print(rsf_median)
print(aft_std)
print(cox_std)
print(rsf_std)

"""## 2) Demonstrations: Individual Prediction on Test set"""

df_test

test_1 = df_test.drop(columns=['SubjectID','time_opt', 'status_opt'])

tes_1_aft = test_1[['Age', 'onset_delta', 'fvc_mean',
       'mean_Q1_2_3_mouth', 'mean_Q7_Turning_in_Bed',
       'slope_Q1_Speech', 'slope_Q3_Swallowing', 
        'weight_slope']]

aft = WeibullAFTFitter(penalizer = 0.2, l1_ratio = 0.2)
aft.fit(df_train_finalaft, duration_col='time_opt', event_col='status_opt', ancillary=False)

fig, ax = plt.subplots(figsize=(13,7))
result_aft = aft.predict_survival_function(tes_1_aft)
ax = sns.lineplot(data = result_aft)
ax.set(xlabel='Time in days', ylabel='Survival probability')
ax.set_title("AFT")

tes_1_cox = test_1[['Age', 'onset_delta', 'fvc_mean',
       'mean_Q1_2_3_mouth', 'mean_Q7_Turning_in_Bed',
       'slope_Q1_Speech', 'slope_Q3_Swallowing', 
        'weight_slope']]

cph = CoxPHFitter(penalizer=0.1, l1_ratio = 0.2)
cph.fit(df_train_finalcox, 'time_opt', event_col='status_opt')

fig, ax = plt.subplots(figsize=(13,7))
result_cph = cph.predict_survival_function(tes_1_cox)
ax = sns.lineplot(data = result_cph)
ax.set(xlabel='Time in days', ylabel='Survival probability')
ax.set_title("COXPH")

tes_1_rsf = test_1[['onset_delta', 'fvc_mean',
       'mean_Q1_2_3_mouth', 'mean_Q7_Turning_in_Bed',
       'slope_Q1_Speech', 'slope_Q3_Swallowing', 
        'weight_slope']]

rsf = RandomSurvivalForest(n_estimators=100,
                           min_samples_split=8,
                           min_samples_leaf=18,
                           max_features="auto",
                           n_jobs=-1,
                           random_state=20)
rsf.fit(df_train_finalrsf.iloc[:,:-2], y_train_rsf)

result_rsf = rsf.predict_survival_function(tes_1_rsf, return_array=True)
fig, ax = plt.subplots(figsize=(13,7))
for i, s in enumerate(result_rsf):
    plt.step(rsf.event_times_, s, where="post")
    
plt.legend(labels = list(test_1.index))
plt.ylabel("Survival probability")
plt.xlabel("Time in days")
plt.title("RSF")
plt.show()

"""# 3) Group Stratification by median predicted time

## (1) Accelerated Failure Time model
"""

# Extract median probability time
aft_median = pd.concat([opt_data['SubjectID'],aft.predict_median(df_train_finalaft)], axis=1)
aft_median

# Check how many subjects have infinity values on median prob time
print('There are ' + str(aft_median.replace([np.inf,-np.inf], np.nan).isnull().sum(axis = 0).iloc[1]) + ' inf values in aft_median')

sns.histplot(x = aft_median[0])

# Find 25 and 75 percentile range of median prob time
aft_median.describe()

# Categorize into 3 group based on interquartile range
aft_slow_list = list(aft_median[aft_median[0] >= 793.393296]['SubjectID'])
aft_intermediate_list = list(aft_median[(aft_median[0] >= 351.769077) & (cph_median[0.5] < 793.393296)]['SubjectID'])
aft_rapid_list = list(aft_median[aft_median[0]  < 351.769077]['SubjectID'])
X_aft_slow = opt_data[opt_data['SubjectID'].isin(aft_slow_list)]
X_aft_intermediate = opt_data[opt_data['SubjectID'].isin(aft_intermediate_list)]
X_aft_rapid = opt_data[opt_data['SubjectID'].isin(aft_rapid_list)]

# Create a representative virtual patient with each feature's mean value
VIRT_aft_slow = pd.DataFrame(X_aft_slow.mean()).transpose().iloc[:, 1:-2][finalaft_feature_list]
VIRT_aft_intermediate = pd.DataFrame(X_aft_intermediate.mean()).transpose().iloc[:, 1:-2][finalaft_feature_list]
VIRT_aft_rapid = pd.DataFrame(X_aft_rapid.mean()).transpose().iloc[:, 1:-2][finalaft_feature_list]

result_aft_slow = aft.predict_survival_function(VIRT_aft_slow)
result_aft_intermediate = aft.predict_survival_function(VIRT_aft_intermediate)
result_aft_rapid = aft.predict_survival_function(VIRT_aft_rapid)

# Compare KM curve and AFT-prediction curve in each group
# KM in solid lines, pred curve in dotted lines
plt.figure(figsize=(25, 7))

plt.subplot(131)
OPT = kmf.fit(X_aft_slow["time_opt"], X_aft_slow["status_opt"], label='Optimal time to gastrostomy', alpha=1)
ax_kmf = OPT.plot(color='#3359cc', linewidth=1.5)
plt.title("Slow")
plt.plot(result_aft_slow.index, result_aft_slow[0], marker='None', color='#80b5ff', linestyle="--", linewidth=1.8)
plt.title("AFT")
plt.xlim([-40,2000])
plt.ylim([0,1.05])

plt.subplot(132)
OPT = kmf.fit(X_aft_intermediate["time_opt"], X_aft_intermediate["status_opt"], label='Optimal time to gastrostomy', alpha=1)
ax_kmf = OPT.plot(color='#3359cc', linewidth=1.5)
plt.title("Intermediate")
plt.plot(result_aft_intermediate.index, result_aft_intermediate[0], marker='None', color='#80b5ff', linestyle="--", linewidth=1.8)
plt.title("AFT")
plt.xlim([-40,2000])
plt.ylim([0,1.05])

plt.subplot(133)
OPT = kmf.fit(X_aft_rapid["time_opt"], X_aft_rapid["status_opt"], label='Optimal time to gastrostomy', alpha=1)
ax_kmf = OPT.plot(color='#3359cc', linewidth=1.5)
plt.title("Rapid")
plt.plot(result_aft_rapid.index, result_aft_rapid[0], marker='None', color='#80b5ff', linestyle="--", linewidth=1.8)
plt.title("AFT")
plt.xlim([-40,2000])
plt.ylim([0,1.05])

plt.suptitle('Prediction on a virtual subject filled with mean values: AFT', fontsize=20)

plt.show()

"""## (2) Cox proportional hazard model"""

# Extract median probability time
cph_median = pd.concat([opt_data['SubjectID'],cph.predict_median(df_train_finalcox)], axis=1)
cph_median

# Check how many subjects have infinity values on median prob time
print('There are ' + str(cph_median.replace([np.inf,-np.inf], np.nan).isnull().sum(axis = 0).iloc[1]) + ' inf values in cph_median')

# For classification purpose, inf values are replaced to 'max + 200'
cph_median_max = cph_median.replace([np.inf,-np.inf], np.nan).dropna(subset=[0.5],how='all')[0.5].max()
cph_inf = cph_median_max + 200
cph_median = cph_median.replace([np.inf,-np.inf], cph_inf)

sns.histplot(x = cph_median[0.5])

# Find 25 and 75 percentile range of median prob time
cph_median.describe()

# Categorize into 3 group based on interquartile range
cph_slow_list = list(cph_median[cph_median[0.5] >= 820]['SubjectID'])
cph_intermediate_list = list(cph_median[(cph_median[0.5] >= 361) & (cph_median[0.5] < 820)]['SubjectID'])
cph_rapid_list = list(cph_median[cph_median[0.5]  < 361]['SubjectID'])
X_cph_slow = opt_data[opt_data['SubjectID'].isin(cph_slow_list)]
X_cph_intermediate = opt_data[opt_data['SubjectID'].isin(cph_intermediate_list)]
X_cph_rapid = opt_data[opt_data['SubjectID'].isin(cph_rapid_list)]

# Create a representative virtual patient with each feature's mean value
VIRT_cph_slow = pd.DataFrame(X_cph_slow.mean()).transpose().iloc[:, 1:-2][finalcox_feature_list]
VIRT_cph_intermediate = pd.DataFrame(X_cph_intermediate.mean()).transpose().iloc[:, 1:-2][finalcox_feature_list]
VIRT_cph_rapid = pd.DataFrame(X_cph_rapid.mean()).transpose().iloc[:, 1:-2][finalcox_feature_list]

result_cph_slow = cph.predict_survival_function(VIRT_cph_slow)
result_cph_intermediate = cph.predict_survival_function(VIRT_cph_intermediate)
result_cph_rapid = cph.predict_survival_function(VIRT_cph_rapid)

from lifelines import KaplanMeierFitter
kmf = KaplanMeierFitter()

from lifelines.utils import median_survival_times

# Compare KM curve and Cox-prediction curve in each group
# KM in solid lines, pred curve in dotted lines
plt.figure(figsize=(25, 7))

plt.subplot(131)
OPT = kmf.fit(X_cph_slow["time_opt"], X_cph_slow["status_opt"], label='Optimal time to gastrostomy', alpha=1)
ax_kmf = OPT.plot(color='#853C3C', linewidth=1.5)
plt.title("Slow")
plt.plot(result_cph_slow.index, result_cph_slow, marker='None', color='#CD7070', linestyle='--', linewidth=1.8)
plt.xlim([-40,2000])
plt.ylim([0,1.05])


plt.subplot(132)
OPT = kmf.fit(X_cph_intermediate["time_opt"], X_cph_intermediate["status_opt"], label='Optimal time to gastrostomy', alpha=1)
ax_kmf = OPT.plot(color='#853C3C', linewidth=1.5)
plt.title("Intermediate")
plt.plot(result_cph_intermediate.index, result_cph_intermediate, marker='None', color='#CD7070', linestyle='--', linewidth=1.8)
plt.xlim([-40,2000])
plt.ylim([0,1.05])


plt.subplot(133)
OPT = kmf.fit(X_cph_rapid["time_opt"], X_cph_rapid["status_opt"], label='Optimal time to gastrostomy', alpha=1)
ax_kmf = OPT.plot(color='#853C3C', linewidth=1.8)
plt.title("Rapid")
plt.plot(result_cph_rapid.index, result_cph_rapid, marker='None', color='#CD7070', linestyle='--',linewidth=1.8)
plt.xlim([-40,2000])
plt.ylim([0,1.05])

plt.suptitle('Group Stratification: CoxPH', fontsize=20)
plt.show()

"""## (3) Random Survival Forests model"""

def predict_rsf_median(data):
  result = rsf.predict_survival_function(data.to_numpy().reshape(1, -1), return_array = True)
  result = np.squeeze(result)
  time_result = pd.DataFrame({'time' : rsf.event_times_, 'p' : result })

  if time_result[time_result['p'] <= 0.5].count()['time'] == 0:
    median = np.inf
  else:
    median = time_result[time_result['p'] <= 0.5].iloc[0,0]

  return median

# Extract median probability time
rsf_median_list = []
for i in range(df_train_finalrsf.shape[0]):
  rsf_median_list.append(predict_rsf_median(df_train_finalrsf.iloc[i,:-2]))

rsf_median_list

subjectID = opt_data['SubjectID'].copy()
subjectID.index = range(len(subjectID))
subjectID

rsf_median = pd.concat([subjectID, pd.Series(rsf_median_list)], axis=1)
rsf_median

# Check how many subjects have infinity values on median prob time
print('There are ' + str(rsf_median.replace([np.inf,-np.inf], np.nan).isnull().sum(axis = 0).iloc[1]) + ' inf values in rsf_median')

# For classification purpose, inf values are replaced to 'max + 200'
rsf_median_max = rsf_median.replace([np.inf,-np.inf], np.nan).dropna(subset=[0],how='all')[0].max()
rsf_inf = rsf_median_max + 200
rsf_median = rsf_median.replace([np.inf,-np.inf], rsf_inf)

sns.histplot(x = rsf_median[0])

# Find 25 and 75 percentile range of median prob time
rsf_median.describe()

# Categorize into 3 group based on interquartile range
rsf_slow_list = list(rsf_median[rsf_median[0] >= 1234]['SubjectID'])
rsf_intermediate_list = list(rsf_median[(rsf_median[0] >= 309) & (rsf_median[0] < 1234)]['SubjectID'])
rsf_rapid_list = list(rsf_median[rsf_median[0]  < 309]['SubjectID'])
X_rsf_slow = opt_data[opt_data['SubjectID'].isin(rsf_slow_list)]
X_rsf_intermediate = opt_data[opt_data['SubjectID'].isin(rsf_intermediate_list)]
X_rsf_rapid = opt_data[opt_data['SubjectID'].isin(rsf_rapid_list)]

# Create a representative virtual patient with each feature's mean value
VIRT_rsf_slow = pd.DataFrame(X_rsf_slow.mean()).transpose().iloc[:, 1:-2][finalrsf_feature_list]
VIRT_rsf_intermediate = pd.DataFrame(X_rsf_intermediate.mean()).transpose().iloc[:, 1:-2][finalrsf_feature_list]
VIRT_rsf_rapid = pd.DataFrame(X_rsf_rapid.mean()).transpose().iloc[:, 1:-2][finalrsf_feature_list]

result_rsf_slow = rsf.predict_survival_function(VIRT_rsf_slow, return_array=True)
result_rsf_intermediate = rsf.predict_survival_function(VIRT_rsf_intermediate, return_array=True)
result_rsf_rapid = rsf.predict_survival_function(VIRT_rsf_rapid, return_array=True)

# Compare KM curve and RSF-prediction curve in each group
# KM in solid lines, pred curve in dotted lines
plt.figure(figsize=(25, 7))

plt.subplot(131)
OPT = kmf.fit(X_rsf_slow["time_opt"], X_rsf_slow["status_opt"], label='Optimal time to gastrostomy', alpha=1)
ax_kmf = OPT.plot(color='#009000', linewidth=1.5)
plt.title("Slow")
for i, s in enumerate(result_rsf_slow):
    plt.step(rsf.event_times_, s, where="post", color='#8FCC52', linestyle='--', linewidth=1.8)
plt.xlim([-40,2000])
plt.ylim([0,1.05])


plt.subplot(132)
OPT = kmf.fit(X_rsf_intermediate["time_opt"], X_rsf_intermediate["status_opt"], label='Optimal time to gastrostomy', alpha=1)
ax_kmf = OPT.plot(color='#009000', linewidth=1.5)
plt.title("Intermediate")
for i, s in enumerate(result_rsf_intermediate):
    plt.step(rsf.event_times_, s, where="post", color='#8FCC52', linestyle='--', linewidth=1.8)
plt.xlim([-40,2000])
plt.ylim([0,1.05])


plt.subplot(133)
OPT = kmf.fit(X_rsf_rapid["time_opt"], X_rsf_rapid["status_opt"], label='Optimal time to gastrostomy', alpha=1)
ax_kmf = OPT.plot(color='#009000', linewidth=1.5)
plt.title("Rapid")
for i, s in enumerate(result_rsf_rapid):
    plt.step(rsf.event_times_, s, where="post", color='#8FCC52', linestyle='--', linewidth=1.8)
plt.xlim([-40,2000])
plt.ylim([0,1.05])

plt.suptitle('Group Stratification: RSF', fontsize=20)
plt.show()

"""## (4) Comparison"""

# Based on group stratification graphs, 25%, 50%, 75% prob time is calculated in each curve
kmf1 = KaplanMeierFitter()
kmf2 = KaplanMeierFitter()
kmf3 = KaplanMeierFitter()
kmf4 = KaplanMeierFitter()
kmf5 = KaplanMeierFitter()
kmf6 = KaplanMeierFitter()
kmf7 = KaplanMeierFitter()
kmf8 = KaplanMeierFitter()
kmf9 = KaplanMeierFitter()


cph_KM_rapid = kmf1.fit(X_cph_fast["time_opt"], X_cph_fast["status_opt"])
cph_KM_intermediate = kmf2.fit(X_cph_medium["time_opt"], X_cph_medium["status_opt"])
cph_KM_slow = kmf3.fit(X_cph_slow["time_opt"], X_cph_slow["status_opt"])

aft_KM_rapid = kmf4.fit(X_aft_fast["time_opt"], X_aft_fast["status_opt"])
aft_KM_intermediate = kmf5.fit(X_aft_medium["time_opt"], X_aft_medium["status_opt"])
aft_KM_slow = kmf6.fit(X_aft_slow["time_opt"], X_aft_slow["status_opt"])

rsf_KM_slow = kmf7.fit(X_rsf_slow["time_opt"], X_rsf_slow["status_opt"])
rsf_KM_intermediate = kmf8.fit(X_rsf_medium["time_opt"], X_rsf_medium["status_opt"])
rsf_KM_rapid = kmf9.fit(X_rsf_fast["time_opt"], X_rsf_fast["status_opt"])

def predict_rsf_percentile(data, percentile):
  result = rsf.predict_survival_function(data.to_numpy().reshape(1, -1), return_array = True)
  result = np.squeeze(result)
  time_result = pd.DataFrame({'time' : rsf.event_times_, 'p' : result })

  if time_result[time_result['p'] <= percentile].count()['time'] == 0:
    per = np.inf
  else:
    per = time_result[time_result['p'] <= percentile].iloc[0,0]

  return per

GS_AFT_list = [['KM rapid', aft_KM_rapid.percentile(0.25), aft_KM_rapid.percentile(0.5), aft_KM_rapid.percentile(0.75)],
               ['Aft rapid', aft.predict_percentile(df=VIRT_aft_fast, ancillary=None, p=0.25)[0], aft.predict_median(VIRT_aft_fast)[0], aft.predict_percentile(df=VIRT_aft_fast, ancillary=None, p=0.75)[0]],
               ['KM intermediate', aft_KM_intermediate.percentile(0.25), aft_KM_intermediate.percentile(0.5), aft_KM_intermediate.percentile(0.75)],
               ['Aft intermediate', aft.predict_percentile(df=VIRT_aft_medium, ancillary=None, p=0.25)[0], aft.predict_median(VIRT_aft_medium)[0], aft.predict_percentile(df=VIRT_aft_medium, ancillary=None, p=0.75)[0]],
               ['KM slow', aft_KM_slow.percentile(0.25), aft_KM_slow.percentile(0.5), aft_KM_slow.percentile(0.75)],
               ['Aft slow', aft.predict_percentile(VIRT_aft_slow, ancillary=None, p=0.25)[0], aft.predict_median(VIRT_aft_slow)[0], aft.predict_percentile(VIRT_aft_slow, ancillary=None, p=0.75)[0]]]

GS_COX_list = [['KM rapid', cph_KM_rapid.percentile(0.25), cph_KM_rapid.percentile(0.5), cph_KM_rapid.percentile(0.75)],
               ['Cox rapid', cph.predict_percentile(VIRT_cph_fast, 0.25), cph.predict_median(VIRT_cph_fast), cph.predict_percentile(VIRT_cph_fast, 0.75)],
               ['KM intermediate', cph_KM_intermediate.percentile(0.25), cph_KM_intermediate.percentile(0.5), cph_KM_intermediate.percentile(0.75)],
               ['Cox intermediate', cph.predict_percentile(VIRT_cph_medium, 0.25), cph.predict_median(VIRT_cph_medium), cph.predict_percentile(VIRT_cph_medium, 0.75)],
               ['KM slow', cph_KM_slow.percentile(0.25), cph_KM_slow.percentile(0.5), cph_KM_slow.percentile(0.75)],
               ['Cox slow', cph.predict_percentile(VIRT_cph_slow, 0.25), cph.predict_median(VIRT_cph_slow), cph.predict_percentile(VIRT_cph_slow, 0.75)]]

GS_RSF_list = [['KM rapid', rsf_KM_rapid.percentile(0.25), rsf_KM_rapid.percentile(0.5), rsf_KM_rapid.percentile(0.75)],
               ['Rsf rapid', predict_rsf_percentile(VIRT_rsf_fast, 0.25), predict_rsf_percentile(VIRT_rsf_fast, 0.5), predict_rsf_percentile(VIRT_rsf_fast, 0.75)],
               ['KM intermediate', rsf_KM_intermediate.percentile(0.25), rsf_KM_intermediate.percentile(0.5), rsf_KM_intermediate.percentile(0.75)],
               ['Rsf intermediate', predict_rsf_percentile(VIRT_rsf_medium, 0.25), predict_rsf_percentile(VIRT_rsf_medium, 0.5), predict_rsf_percentile(VIRT_rsf_medium, 0.75)],
               ['KM slow', rsf_KM_slow.percentile(0.25), rsf_KM_slow.percentile(0.5), rsf_KM_slow.percentile(0.75)],
               ['Rsf slow', predict_rsf_percentile(VIRT_rsf_slow, 0.25), predict_rsf_percentile(VIRT_rsf_slow, 0.5), predict_rsf_percentile(VIRT_rsf_slow, 0.75)]]

GS_AFT = pd.DataFrame(GS_AFT_list,columns=['model','25%','50%','75%'])
GS_COX = pd.DataFrame(GS_COX_list,columns=['model','25%','50%','75%'])
GS_RSF = pd.DataFrame(GS_RSF_list,columns=['model','25%','50%','75%'])

GS_AFT

# Thick colored lines represent the interquartile range time to event
# Black dots in the middle represent median probability time to event
import matplotlib as mp
fig, ax = plt.subplots(figsize=(6,8))

plt.xlim([0,2000])
plt.ylim([0,7])
rect1 = mp.patches.Rectangle((GS_AFT.iloc[0,3],5.8), (GS_AFT.iloc[0,1]-GS_AFT.iloc[0,3]), 0.4, edgecolor='white', facecolor='#3359CC')
rect2 = mp.patches.Rectangle((GS_AFT.iloc[1,3],4.8), (GS_AFT.iloc[1,1]-GS_AFT.iloc[1,3]), 0.4, edgecolor='white', facecolor='#80b5ff')
rect3 = mp.patches.Rectangle((GS_AFT.iloc[2,3],3.8), (GS_AFT.iloc[2,1]-GS_AFT.iloc[2,3]), 0.4, edgecolor='white', facecolor='#3359CC')
rect4 = mp.patches.Rectangle((GS_AFT.iloc[3,3],2.8), (GS_AFT.iloc[3,1]-GS_AFT.iloc[3,3]), 0.4, edgecolor='white', facecolor='#80b5ff')
rect5 = mp.patches.Rectangle((GS_AFT.iloc[4,3],1.8), (GS_AFT.iloc[4,1]-GS_AFT.iloc[4,3]), 0.4, edgecolor='white', facecolor='#3359CC')
rect6 = mp.patches.Rectangle((GS_AFT.iloc[5,3],0.8), (GS_AFT.iloc[5,1]-GS_AFT.iloc[5,3]), 0.4, edgecolor='white', facecolor='#80b5ff')
plt.plot(GS_AFT.iloc[0,2],6,'ko')
plt.plot(GS_AFT.iloc[1,2],5,'ko')
plt.plot(GS_AFT.iloc[2,2],4,'ko')
plt.plot(GS_AFT.iloc[3,2],3,'ko')
plt.plot(GS_AFT.iloc[4,2],2,'ko')
plt.plot(GS_AFT.iloc[5,2],1,'ko')

ax.yaxis.set_visible(False)
ax.add_patch(rect1)
ax.add_patch(rect2)
ax.add_patch(rect3)
ax.add_patch(rect4)
ax.add_patch(rect5)
ax.add_patch(rect6)

GS_COX

# Thick colored lines represent the interquartile range time to event
# Black dots in the middle represent median probability time to event
fig, ax = plt.subplots(figsize=(6,8))

plt.xlim([0,2000])
plt.ylim([0,7])
rect1 = mp.patches.Rectangle((GS_COX.iloc[0,3],5.8), (GS_COX.iloc[0,1]-GS_COX.iloc[0,3]), 0.4, edgecolor='white', facecolor='#853C3C')
rect2 = mp.patches.Rectangle((GS_COX.iloc[1,3],4.8), (GS_COX.iloc[1,1]-GS_COX.iloc[1,3]), 0.4, edgecolor='white', facecolor='#CD7070')
rect3 = mp.patches.Rectangle((GS_COX.iloc[2,3],3.8), (GS_COX.iloc[2,1]-GS_COX.iloc[2,3]), 0.4, edgecolor='white', facecolor='#853C3C')
rect4 = mp.patches.Rectangle((GS_COX.iloc[3,3],2.8), (GS_COX.iloc[3,1]-GS_COX.iloc[3,3]), 0.4, edgecolor='white', facecolor='#CD7070')
rect5 = mp.patches.Rectangle((GS_COX.iloc[4,3],1.8), (GS_COX.iloc[4,1]-GS_COX.iloc[4,3]), 0.4, edgecolor='white', facecolor='#853C3C')
rect6 = mp.patches.Rectangle((GS_COX.iloc[5,3],0.8), 2000, 0.4, edgecolor='white', facecolor='#CD7070')
plt.plot(GS_COX.iloc[0,2],6,'ko')
plt.plot(GS_COX.iloc[1,2],5,'ko')
plt.plot(GS_COX.iloc[2,2],4,'ko')
plt.plot(GS_COX.iloc[3,2],3,'ko')
plt.plot(GS_COX.iloc[4,2],2,'ko')
plt.plot(GS_COX.iloc[5,2],1,'ko')

ax.yaxis.set_visible(False)
ax.add_patch(rect1)
ax.add_patch(rect2)
ax.add_patch(rect3)
ax.add_patch(rect4)
ax.add_patch(rect5)
ax.add_patch(rect6)

GS_RSF

# Thick colored lines represent the interquartile range time to event
# Black dots in the middle represent median probability time to event
fig, ax = plt.subplots(figsize=(6,8))

plt.xlim([0,2000])
plt.ylim([0,7])
rect1 = mp.patches.Rectangle((GS_RSF.iloc[0,3],5.8), (GS_RSF.iloc[0,1]-GS_RSF.iloc[0,3]), 0.4, edgecolor='white', facecolor='#009000')
rect2 = mp.patches.Rectangle((GS_RSF.iloc[1,3],4.8), (GS_RSF.iloc[1,1]-GS_RSF.iloc[1,3]), 0.4, edgecolor='white', facecolor='#8FCC52')
rect3 = mp.patches.Rectangle((GS_RSF.iloc[2,3],3.8), (GS_RSF.iloc[2,1]-GS_RSF.iloc[2,3]), 0.4, edgecolor='white', facecolor='#009000')
rect4 = mp.patches.Rectangle((GS_RSF.iloc[3,3],2.8), 2000, 0.4, edgecolor='white', facecolor='#8FCC52')
rect5 = mp.patches.Rectangle((GS_RSF.iloc[4,3],1.8), (GS_RSF.iloc[4,1]-GS_RSF.iloc[4,3]), 0.4, edgecolor='white', facecolor='#009000')
rect6 = mp.patches.Rectangle((GS_RSF.iloc[5,3],0.8), 2000, 0.4, edgecolor='white', facecolor='#8FCC52')
plt.plot(GS_RSF.iloc[0,2],6,'ko')
plt.plot(GS_RSF.iloc[1,2],5,'ko')
plt.plot(GS_RSF.iloc[2,2],4,'ko')
plt.plot(GS_RSF.iloc[3,2],3,'ko')
plt.plot(GS_RSF.iloc[4,2],2,'ko')

ax.yaxis.set_visible(False)
ax.add_patch(rect1)
ax.add_patch(rect2)
ax.add_patch(rect3)
ax.add_patch(rect4)
ax.add_patch(rect5)
ax.add_patch(rect6)